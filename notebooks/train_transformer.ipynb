{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0977906d-749c-4a97-9482-d71c3d95111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # required to use harmony package\n",
    "\n",
    "from harmony.models.seq2seq import TransformerEncoder, TransformerDecoder, Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fcec00-8902-4532-9029-8c598ff072ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from skimage.util import view_as_windows\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5a2663-c74a-4ab2-8e12-38524efdc2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc1333-c314-4070-b2a4-ff5791b810aa",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3abde40d-7c2b-4c77-bee3-78910e38a0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 450\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/local/thiago.poppe/beatles_vocab.h5') as vocab:\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "print('Vocab size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1747d08-4fba-49ab-adb0-e7ed9ae9eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeatlesDataset(Dataset):\n",
    "    def __init__(self, split='train'):\n",
    "        self.filepath = f'/local/thiago.poppe/beatles_{split}_chunks.h5'\n",
    "        with h5py.File(self.filepath, 'r') as h5:\n",
    "            self.chunk_ids = list(h5.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.chunk_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk_id = self.chunk_ids[idx]\n",
    "        with h5py.File(self.filepath, 'r') as h5:\n",
    "            harmony = h5[chunk_id]['harmony'][:]\n",
    "            spec = h5[chunk_id]['spectrogram'][:].T  # transformer expects (seq_length, n_features)\n",
    "\n",
    "        return spec, harmony\n",
    "\n",
    "train_dataset = BeatlesDataset(split='train')\n",
    "valid_dataset = BeatlesDataset(split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1027acf-c8dc-4548-b207-addd5dd9c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataloader: 50\n",
      "Length of valid dataloader: 12\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batches):\n",
    "    specs = [torch.from_numpy(batch[0]).float() for batch in batches]\n",
    "    specs = pad_sequence(specs, batch_first=True)\n",
    "    padding_mask = (specs == 0)[..., 0]\n",
    "    \n",
    "    harmony = [torch.from_numpy(batch[1]) for batch in batches]\n",
    "    harmony = torch.stack(harmony)\n",
    "\n",
    "    return specs, harmony, padding_mask\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "print('Length of train dataloader:', len(train_dataloader))\n",
    "print('Length of valid dataloader:', len(valid_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8f662-52d8-4f91-ade6-14c79330fd89",
   "metadata": {},
   "source": [
    "## Definindo modelo seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e00f5b2-5873-4f52-9cea-e2886ac98161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters: 9210\n",
      "Seq2SeqTransformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=16, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): LinearEmbeddingLayer(\n",
      "      (embedding): Linear(in_features=6, out_features=8, bias=True)\n",
      "      (pos_encoding): PositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (fc): Linear(in_features=8, out_features=450, bias=True)\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=16, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): EmbeddingLayer(\n",
      "      (embedding): Embedding(450, 8)\n",
      "      (pos_encoding): PositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = TransformerEncoder(in_features=6, embedding_size=8, num_heads=1, dim_feedforward=16, num_layers=1)\n",
    "decoder = TransformerDecoder(vocab_size=vocab_size, embedding_size=8, num_heads=1, dim_feedforward=16, num_layers=1)\n",
    "model = Seq2SeqTransformer(encoder, decoder).to(device)\n",
    "\n",
    "print('Number of learnable parameters:', sum(p.numel() for p in model.parameters()))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa35fb-76f5-47db-9a48-eb98e9a3f835",
   "metadata": {},
   "source": [
    "Aqui iremos testar o modelo com um dado aleatório, apenas para ver se tudo está funcionando.\n",
    "- Tamanho da entrada: `(batch_size, seq_length, in_features) -> (4, 128, 6)`\n",
    "- Tamanho da saída: `(batch_size, seq_length) -> (4, 64)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20378723-9e16-4dd4-b81a-d6ff4466503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da sáida: torch.Size([4, 64, 450])\n"
     ]
    }
   ],
   "source": [
    "src = torch.rand(4, 128, 6).to(device)\n",
    "tgt = torch.randint(low=0, high=vocab_size, size=(4, 64)).long().to(device)\n",
    "\n",
    "padding_mask = torch.zeros(4, 128).bool().to(device)  # padding mask da entrada\n",
    "tgt_causal_mask = nn.Transformer.generate_square_subsequent_mask(64).to(device)  # máscara causal tem que ter o mesmo tamanho do seq_length da saída\n",
    "\n",
    "outputs = model(src, tgt, tgt_mask=tgt_causal_mask, padding_mask=padding_mask)\n",
    "print('Tamanho da sáida:', outputs.shape)  # (batch_size, seq_length, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05ace2-2f67-4333-b877-6d4737e1aa10",
   "metadata": {},
   "source": [
    "## Treinando modelo seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e9651c-4654-4510-863c-f9c4e2618e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, criterion, optimizer):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for specs, harmony, padding_mask in train_dataloader:\n",
    "        specs = specs.to(device)\n",
    "        \n",
    "        with h5py.File('/local/thiago.poppe/beatles_vocab.h5') as vocab:\n",
    "            batch_size = harmony.size(0)\n",
    "            sos_tokens = torch.full((batch_size, 1), fill_value=vocab['<sos>'][()])\n",
    "            eos_tokens = torch.full((batch_size, 1), fill_value=vocab['<eos>'][()])\n",
    "            \n",
    "            decoder_input = torch.cat([sos_tokens, harmony], dim=1).to(device)\n",
    "            decoder_target = torch.cat([harmony, eos_tokens], dim=1).to(device)\n",
    "\n",
    "        padding_mask = padding_mask.to(device)\n",
    "        tgt_causal_mask = nn.Transformer.generate_square_subsequent_mask(decoder_input.size(1)).to(device)\n",
    "        \n",
    "        outputs = model(specs, decoder_input, tgt_mask=tgt_causal_mask, padding_mask=padding_mask)\n",
    "        loss = criterion(outputs.transpose(1,2), decoder_target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        train_acc += torch.sum(predictions.flatten() == decoder_target.flatten()) / len(predictions.flatten())\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def validate(model, valid_dataloader, criterion):\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "\n",
    "    # Por algum motivo não rodou com model.eval() aqui e num_heads = 1... vou ver com mais calma o pq depois!\n",
    "    # model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for specs, harmony, padding_mask in valid_dataloader:\n",
    "            specs = specs.to(device)\n",
    "            \n",
    "            with h5py.File('/local/thiago.poppe/beatles_vocab.h5') as vocab:\n",
    "                batch_size = harmony.size(0)\n",
    "                sos_tokens = torch.full((batch_size, 1), fill_value=vocab['<sos>'][()])\n",
    "                eos_tokens = torch.full((batch_size, 1), fill_value=vocab['<eos>'][()])\n",
    "                \n",
    "                decoder_input = torch.cat([sos_tokens, harmony], dim=1).to(device)\n",
    "                decoder_target = torch.cat([harmony, eos_tokens], dim=1).to(device)\n",
    "    \n",
    "            padding_mask = padding_mask.to(device)\n",
    "            tgt_causal_mask = nn.Transformer.generate_square_subsequent_mask(decoder_input.size(1)).to(device)\n",
    "            \n",
    "            outputs = model(specs, decoder_input, tgt_mask=tgt_causal_mask, padding_mask=padding_mask)\n",
    "            loss = criterion(outputs.transpose(1,2), decoder_target)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            valid_acc += torch.sum(predictions.flatten() == decoder_target.flatten()) / len(predictions.flatten())\n",
    "    \n",
    "        valid_loss /= len(valid_dataloader)\n",
    "        valid_acc /= len(valid_dataloader)\n",
    "        \n",
    "        return valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18888fa5-c7ab-4118-b69b-b9aa7ecbc5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100:\n",
      " - Train loss: 4.88566, train accuracy: 0.13386\n",
      " - Valid loss: 5.11720, valid accuracy: 0.18678\n",
      "\n",
      "Epoch 10/100:\n",
      " - Train loss: 3.92718, train accuracy: 0.26294\n",
      " - Valid loss: 4.52776, valid accuracy: 0.32019\n",
      "\n",
      "Epoch 15/100:\n",
      " - Train loss: 3.31506, train accuracy: 0.36389\n",
      " - Valid loss: 4.25788, valid accuracy: 0.36434\n",
      "\n",
      "Epoch 20/100:\n",
      " - Train loss: 2.88806, train accuracy: 0.43604\n",
      " - Valid loss: 4.15363, valid accuracy: 0.39367\n",
      "\n",
      "Epoch 25/100:\n",
      " - Train loss: 2.57766, train accuracy: 0.50606\n",
      " - Valid loss: 4.13561, valid accuracy: 0.41482\n",
      "\n",
      "Epoch 30/100:\n",
      " - Train loss: 2.32899, train accuracy: 0.56241\n",
      " - Valid loss: 4.08987, valid accuracy: 0.43534\n",
      "\n",
      "Epoch 35/100:\n",
      " - Train loss: 2.13842, train accuracy: 0.60636\n",
      " - Valid loss: 4.06285, valid accuracy: 0.45729\n",
      "\n",
      "Epoch 40/100:\n",
      " - Train loss: 1.97911, train accuracy: 0.64349\n",
      " - Valid loss: 4.14391, valid accuracy: 0.45841\n",
      "\n",
      "Epoch 45/100:\n",
      " - Train loss: 1.85372, train accuracy: 0.67543\n",
      " - Valid loss: 4.08670, valid accuracy: 0.48037\n",
      "\n",
      "Epoch 50/100:\n",
      " - Train loss: 1.74265, train accuracy: 0.70022\n",
      " - Valid loss: 4.02262, valid accuracy: 0.50737\n",
      "\n",
      "Epoch 55/100:\n",
      " - Train loss: 1.65183, train accuracy: 0.72325\n",
      " - Valid loss: 4.19337, valid accuracy: 0.49575\n",
      "\n",
      "Epoch 60/100:\n",
      " - Train loss: 1.57805, train accuracy: 0.73679\n",
      " - Valid loss: 4.09026, valid accuracy: 0.51955\n",
      "\n",
      "Epoch 65/100:\n",
      " - Train loss: 1.50406, train accuracy: 0.75179\n",
      " - Valid loss: 4.25127, valid accuracy: 0.52396\n",
      "\n",
      "Epoch 70/100:\n",
      " - Train loss: 1.44852, train accuracy: 0.76207\n",
      " - Valid loss: 4.24571, valid accuracy: 0.53421\n",
      "\n",
      "Epoch 75/100:\n",
      " - Train loss: 1.39619, train accuracy: 0.77327\n",
      " - Valid loss: 4.32659, valid accuracy: 0.53558\n",
      "\n",
      "Epoch 80/100:\n",
      " - Train loss: 1.36167, train accuracy: 0.78156\n",
      " - Valid loss: 4.43176, valid accuracy: 0.55024\n",
      "\n",
      "Epoch 85/100:\n",
      " - Train loss: 1.31998, train accuracy: 0.78966\n",
      " - Valid loss: 4.43417, valid accuracy: 0.55433\n",
      "\n",
      "Epoch 90/100:\n",
      " - Train loss: 1.27706, train accuracy: 0.80080\n",
      " - Valid loss: 4.44586, valid accuracy: 0.56755\n",
      "\n",
      "Epoch 95/100:\n",
      " - Train loss: 1.24798, train accuracy: 0.80623\n",
      " - Valid loss: 4.60573, valid accuracy: 0.55529\n",
      "\n",
      "Epoch 100/100:\n",
      " - Train loss: 1.21366, train accuracy: 0.81117\n",
      " - Valid loss: 4.57425, valid accuracy: 0.56875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss, train_acc = train(model, train_dataloader, criterion, optimizer)\n",
    "    valid_loss, valid_acc = validate(model, valid_dataloader, criterion)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch {epoch}/{num_epochs}:')\n",
    "        print(f' - Train loss: {train_loss:.5f}, train accuracy: {train_acc:.5f}')\n",
    "        print(f' - Valid loss: {valid_loss:.5f}, valid accuracy: {valid_acc:.5f}', end='\\n\\n')\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        valid_accs.append(valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca18c5-5b82-4d5b-bb4a-6df1d301a966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
